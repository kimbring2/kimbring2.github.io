# Absract
The aim of this project is to try a tower stacking game using Lynxmotion's AL5D robot arm and a commonly used webcam.

<img src="/assets/al5d/manipulator_example_1.gif" width="270">

The robot arm use a general USB Webcam to ascertain information such as the position, color and distance of blocks and dice. Also, I use monocular depth estimation method to ascertain distance instead of using a depth camera for saving budget. 

<img src="/assets/al5d/monodepth_example_1.gif" width="600">

# Table of Contents
1. [INTRODUCTION](#introduction)
2. [PRELIMINARIES](#preliminaries)
    1. [Hardware Description](#hardware_description)
    2. [Robot Arm Control](#robot_arm_control)
    3. [Tower Game Rule](#tower_game_rule)
    4. [Depth Estimation](#depth_estimation)

3. [PLAYING A BLOCK STACKING GAME USING AFFORDABLE MANIPULATOR AND CAMERA](#play_game_affordable_hardware)
4. [DEEP LEARNING METHOD](#deep_learning_method)
    1. [Model-Based Deep Reinforcement Learning](#model_based_rl)
    2. [Monocular Depth Estimation](#mono_depth_estimation)
5. [DISCUSSION](#discussion)
6. [CONCLUSION](#conclusion)
7. [REFERENCE](#reference)

<a name="introduction"></a>
# INTRODUCTION

<a name="preliminaries"></a>
# PRELIMINARIES

<a name="hardware_description"></a>
## Hardware Description
1. [Lynxmotion AL5D 4 Degrees of Freedom Robotic Arm Combo Kit (BotBoarduino)](https://www.robotshop.com/en/lynxmotion-al5d-4-degrees-freedom-robotic-arm-combo-kit.html)

2. [Logitech Webcam](https://www.amazon.com/Logitech-Webcam-Pro-C920-960-000769/dp/B00H2DK80U/ref=sr_1_2?keywords=logitech+Carl+Zeiss+Tessar&qid=1578386836&sr=8-2)

3. [Coogam Wooden Tower Stacking Game](https://www.amazon.com/gp/product/B07WZDNV49/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&psc=1)

<a name="robot_arm_control"></a>
## Robot Arm Structure
<img src="/assets/al5d/5dof_arm_robot.png" width="600">

<a name="tower_game_rule"></a>
## Game Rule
<img src="/assets/al5d/tower_rule.jpg" width="600">

<a name="software"></a>
## Code
1. [Arduino code for BotBoarduino](https://github.com/kimbring2/al5d_tower_game/blob/master/AL5d_code.ino)
2. [Python code for arm robot and webcam](https://github.com/kimbring2/al5d_tower_game/blob/master/AL5d_code.ino)

<a name="dataset"></a>
## Dataset
The robot must detect the blocks in the picutre. Even when multiple blocks overlap, each block must be detected. Thus, I decide to use a Mask R-CNN that has a segmentaion function in addition to detection.

1. [Dataset for Mask R-CNN](https://github.com/kimbring2/al5d_tower_game/tree/master/data)

First, I create a data set by arranging actual blocks to be used at various angles and taking pictures. Thereafter, labeling is performed using VGG Image Annotator.

<img src="/assets/al5d/al5d_mrcnn_1.png" width="600">
<img src="/assets/al5d/al5d_mrcnn_2.png" width="600">

<a name="play_game_affordable_hardware"></a>
# PLAYING A BLOCK STACKING GAME USING AFFORDABLE MANIPULATOR AND CAMERA

<a name="deep_learning_method"></a>
# DEEP LEARNING METHOD

<a name="model_based_rl"></a>
## Model-Based Deep Reinforcement Learning

<a name="mono_depth_estimation"></a>
## Monocular Depth Estimation

<a name="discussion"></a>
# DISCUSSION

<a name="conclusion"></a>
# CONCLUSION

<a name="reference"></a>
# REFERENCE
1. [Deisenroth, Marc & Rasmussen, Carl & Fox, Dieter. (2011). Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning. 10.15607/RSS.2011.VII.008.](https://rse-lab.cs.washington.edu/papers/robot-rl-rss-11.pdf)
2. [Alhashim, I., & Wonka, P. (2018). High Quality Monocular Depth Estimation via Transfer Learning. arXiv preprint arXiv:1812.11941.](https://arxiv.org/abs/1812.11941)
3. [Waleed Abdulla. (2018). Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow. GitHub repository](https://github.com/matterport/Mask_RCNN)
